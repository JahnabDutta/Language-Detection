{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FvAJc1-kpWZL"
      },
      "outputs": [],
      "source": [
        "path = 'resources/Language Detection.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n6Ugfx-PpXKt"
      },
      "outputs": [],
      "source": [
        "import string \n",
        "import re\n",
        "import codecs\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import feature_extraction\n",
        "from sklearn import linear_model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import itertools\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tlJ1123hpfJ6",
        "outputId": "39d565d0-d4b4-44ef-836d-cf6b7ea94c77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nature, in the broadest sense, is the natural...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The study of nature is a large, if not the onl...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Although humans are part of nature, human acti...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10332</th>\n",
              "      <td>ನಿಮ್ಮ ತಪ್ಪು ಏನು ಬಂದಿದೆಯೆಂದರೆ ಆ ದಿನದಿಂದ ನಿಮಗೆ ಒ...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10333</th>\n",
              "      <td>ನಾರ್ಸಿಸಾ ತಾನು ಮೊದಲಿಗೆ ಹೆಣಗಾಡುತ್ತಿದ್ದ ಮಾರ್ಗಗಳನ್...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10334</th>\n",
              "      <td>ಹೇಗೆ ' ನಾರ್ಸಿಸಿಸಮ್ ಈಗ ಮರಿಯನ್ ಅವರಿಗೆ ಸಂಭವಿಸಿದ ಎ...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10335</th>\n",
              "      <td>ಅವಳು ಈಗ ಹೆಚ್ಚು ಚಿನ್ನದ ಬ್ರೆಡ್ ಬಯಸುವುದಿಲ್ಲ ಎಂದು ...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10336</th>\n",
              "      <td>ಟೆರ್ರಿ ನೀವು ನಿಜವಾಗಿಯೂ ಆ ದೇವದೂತನಂತೆ ಸ್ವಲ್ಪ ಕಾಣು...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10337 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text Language\n",
              "0       Nature, in the broadest sense, is the natural...  English\n",
              "1      \"Nature\" can refer to the phenomena of the phy...  English\n",
              "2      The study of nature is a large, if not the onl...  English\n",
              "3      Although humans are part of nature, human acti...  English\n",
              "4      [1] The word nature is borrowed from the Old F...  English\n",
              "...                                                  ...      ...\n",
              "10332  ನಿಮ್ಮ ತಪ್ಪು ಏನು ಬಂದಿದೆಯೆಂದರೆ ಆ ದಿನದಿಂದ ನಿಮಗೆ ಒ...  Kannada\n",
              "10333  ನಾರ್ಸಿಸಾ ತಾನು ಮೊದಲಿಗೆ ಹೆಣಗಾಡುತ್ತಿದ್ದ ಮಾರ್ಗಗಳನ್...  Kannada\n",
              "10334  ಹೇಗೆ ' ನಾರ್ಸಿಸಿಸಮ್ ಈಗ ಮರಿಯನ್ ಅವರಿಗೆ ಸಂಭವಿಸಿದ ಎ...  Kannada\n",
              "10335  ಅವಳು ಈಗ ಹೆಚ್ಚು ಚಿನ್ನದ ಬ್ರೆಡ್ ಬಯಸುವುದಿಲ್ಲ ಎಂದು ...  Kannada\n",
              "10336  ಟೆರ್ರಿ ನೀವು ನಿಜವಾಗಿಯೂ ಆ ದೇವದೂತನಂತೆ ಸ್ವಲ್ಪ ಕಾಣು...  Kannada\n",
              "\n",
              "[10337 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tXt7682DsO8v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Arabic' 'Danish' 'Dutch' 'English' 'French' 'German' 'Greek' 'Hindi'\n",
            " 'Italian' 'Kannada' 'Malayalam' 'Portugeese' 'Russian' 'Spanish'\n",
            " 'Sweedish' 'Tamil' 'Turkish']\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:,0]\n",
        "y = df.iloc[:,1]\n",
        "print(np.unique(y))\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "f0PtItlKwKAW",
        "outputId": "4b733935-dd21-440d-8f76-c673ae65dcf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Language', ylabel='count'>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "sns.countplot(x = df['Language'], data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emAT46QUsVEb",
        "outputId": "0e2b8234-9b20-430e-89cd-bd79e3d099b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' nature  in the broadest sense  is the natural  physical  material world or universe.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_list = []\n",
        "for text in X:\n",
        "    text = re.sub(r'[!@#$(),\"%^*?:;~`0-9]', ' ', text)\n",
        "    text = re.sub(r'[[][  ]]', ' ', text)\n",
        "    text = text.lower()\n",
        "    data_list.append(text)\n",
        "data_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4AQVWiOEw3lg"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data_list, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DIFFERENT VECTORIZATION TECHNIQUES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'resources/glove.6B.50d.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10800/1221037026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'resources/glove.6B.50d.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0membeddings_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/glove.6B.50d.txt'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "path2 = 'resources/glove.6B.50d.txt'\n",
        "embeddings_dict={}\n",
        "with open(path2,'rb') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents = [sent.split() for sent in x_train]\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_NUM_WORDS = 100\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(sents)\n",
        "sequences = tokenizer.texts_to_sequences(sents)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "EMBEDDING_DIM = embeddings_dict.get(b'a').shape[0]\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix_Glove = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dict.get(word.encode(\"utf-8\")) \n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_Glove[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Skip-Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim import models\n",
        "w2v = models.KeyedVectors.load_word2vec_format(\n",
        "'resources/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents = [sent.split() for sent in x_train]\n",
        "custom_model = models.Word2Vec(sents, min_count=1,workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(531270, 1026421)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_model.train(x_train, total_examples=1, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "tfidf = TfidfVectorizer(stop_words='english', analyzer=lambda x: x)\n",
        "logistic = LogisticRegression(solver='liblinear', multi_class='auto')\n",
        "\n",
        "tfidf_logistic = Pipeline([\n",
        "    ('tfidf', tfidf), \n",
        "    ('logistic', logistic)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import randint, uniform\n",
        "\n",
        "w2v_params = {'w2v__size': [100, 150, 200]}\n",
        "tfidf_params = {'tfidf__ngram_range': [(1, 1), (1, 2)]}\n",
        "logistic_params = {'logistic__C': [0.5, 1.0, 1.5]}\n",
        "xgb_params = {'xgb__max_depth': randint(low=3, high=12),\n",
        "              'xgb__colsample_bytree': uniform(loc=0.8, scale=0.2),\n",
        "              'xgb__subsample': uniform(loc=0.8, scale=0.2)}\n",
        "\n",
        "tfidf_logistic_params = {**tfidf_params, **logistic_params}\n",
        "w2v_xgb_params = {**w2v_params, **xgb_params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training: tfidf_logistic\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>train_score</th>\n",
              "      <th>test_score</th>\n",
              "      <th>estimator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tfidf_logistic</td>\n",
              "      <td>0.915951</td>\n",
              "      <td>0.916828</td>\n",
              "      <td>RandomizedSearchCV(cv=3,\\n                   e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model_name  train_score  test_score  \\\n",
              "0  tfidf_logistic     0.915951    0.916828   \n",
              "\n",
              "                                           estimator  \n",
              "0  RandomizedSearchCV(cv=3,\\n                   e...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "cv = 3\n",
        "n_iter = 3\n",
        "random_state = 1234\n",
        "scoring = 'accuracy'\n",
        "\n",
        "all_models = [\n",
        "    ('tfidf_logistic', tfidf_logistic, tfidf_logistic_params)\n",
        "]\n",
        "\n",
        "all_models_info = []\n",
        "for name, model, params in all_models:\n",
        "    print('training:', name)\n",
        "    model_tuned = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=params,\n",
        "        cv=cv,\n",
        "        n_iter=n_iter,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        scoring=scoring,\n",
        "        random_state=random_state,\n",
        "        return_train_score=False\n",
        "    ).fit(x_train, y_train)\n",
        "    \n",
        "    y_test_pred = model_tuned.predict(x_test)\n",
        "    test_score = accuracy_score(y_test, y_test_pred)\n",
        "    info = name, model_tuned.best_score_, test_score, model_tuned\n",
        "    all_models_info.append(info)\n",
        "\n",
        "columns = ['model_name', 'train_score', 'test_score', 'estimator']\n",
        "results = pd.DataFrame(all_models_info, columns=columns)\n",
        "results = (results\n",
        "           .sort_values('test_score', ascending=False)\n",
        "           .reset_index(drop=True))\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PQKnpXbpwYxH"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(3,5),analyzer='char')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents1 = x_train\n",
        "sents2 = x_test\n",
        "transformed1 = tfidf.fit_transform(sents1)\n",
        "transformed2 = tfidf.transform(sents2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents = x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X_count_train = cv.fit_transform(sents)\n",
        "X_count_test = cv.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LATER SHIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "4wzTsYcLwaku",
        "outputId": "baee339e-5add-4b7c-9a6c-3aff2f94eb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__alpha', 'clf__class_prior', 'clf__fit_prior'])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_clf = pipeline.Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "\n",
        "print(text_clf.get_params().keys())\n",
        "text_clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hgAbGZ40jq",
        "outputId": "924c4e48-0d6d-46cc-e638-dd34c4cc6667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       110\n",
            "           1       0.99      0.90      0.94        84\n",
            "           2       0.99      0.97      0.98        96\n",
            "           3       0.83      1.00      0.91       278\n",
            "           4       0.97      0.99      0.98       202\n",
            "           5       1.00      0.98      0.99       101\n",
            "           6       1.00      0.94      0.97        72\n",
            "           7       1.00      0.62      0.77        16\n",
            "           8       0.99      0.96      0.98       142\n",
            "           9       1.00      0.97      0.98        63\n",
            "          10       1.00      0.98      0.99       133\n",
            "          11       0.99      0.99      0.99       143\n",
            "          12       1.00      0.97      0.98       127\n",
            "          13       0.98      0.99      0.99       166\n",
            "          14       0.97      0.99      0.98       137\n",
            "          15       1.00      0.99      1.00       111\n",
            "          16       1.00      0.77      0.87        87\n",
            "\n",
            "    accuracy                           0.96      2068\n",
            "   macro avg       0.98      0.94      0.96      2068\n",
            "weighted avg       0.97      0.96      0.96      2068\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, text_clf.predict(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M61xsnZ97WrF",
        "outputId": "56873232-4549-4392-86c2-5aafe26c3099"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9647001934235977"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, text_clf.predict(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_ET3X03tHIh",
        "outputId": "e1433220-1070-4631-96f8-302d3c15ce2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['resources/cv.pkl']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv = CountVectorizer()\n",
        "X_new = cv.fit_transform(data_list).toarray()\n",
        "joblib.dump(cv, \"resources/cv.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "Uv6ZtF2C-gmU"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8O2YAqutLnF",
        "outputId": "cd0969a8-1acb-44fb-9ef5-16a5f6bbe218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9753384912959381\n"
          ]
        }
      ],
      "source": [
        "model1 = MultinomialNB()\n",
        "model1.fit(x_train, y_train)\n",
        "y_pred = model1.predict(x_test)\n",
        "ac1 = accuracy_score(y_test, y_pred)\n",
        "print(ac1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f2WGTr_ue9K",
        "outputId": "ec5a2051-7660-4f0c-b791-cb79cfa69c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9796905222437138\n"
          ]
        }
      ],
      "source": [
        "model2 = GaussianNB()\n",
        "model2.fit(x_train, y_train)\n",
        "y_pred = model2.predict(x_test)\n",
        "ac2 = accuracy_score(y_test, y_pred)\n",
        "print(ac2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## implimenting NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10337, 17)"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#one hot encode the target variable\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "dummy_y = tf.keras.utils.to_categorical(encoded_Y)\n",
        "dummy_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_Y = encoded_Y.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train = x_train.values\n",
        "# X_test = x_test.values\n",
        "X_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "X_test = dummy_y.reshape(dummy_y.shape[0], dummy_y.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Implement neural network using tensorflow\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=128, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=256, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=128, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "#ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dropout(0.2))\n",
        "ann.add(tf.keras.layers.Dense(units = 17, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3.,  3.,  1., ...,  8., 11.,  1.], dtype=float32)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "324/324 [==============================] - 8s 22ms/step - loss: 0.4371 - accuracy: 0.8926\n",
            "Epoch 2/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0342 - accuracy: 0.9919\n",
            "Epoch 3/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0158 - accuracy: 0.9968\n",
            "Epoch 4/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0120 - accuracy: 0.9969\n",
            "Epoch 5/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0093 - accuracy: 0.9975\n",
            "Epoch 6/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0100 - accuracy: 0.9971\n",
            "Epoch 7/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0119 - accuracy: 0.9966\n",
            "Epoch 8/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 9/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0099 - accuracy: 0.9968\n",
            "Epoch 10/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0088 - accuracy: 0.9974\n"
          ]
        }
      ],
      "source": [
        "ann.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "ann.fit(X_new,encoded_Y, epochs=10, batch_size=32)\n",
        "ann.save('resources/language_predictor.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9622823984526112\n",
            "0.9590643420165255\n"
          ]
        }
      ],
      "source": [
        "dummy_y_test = tf.keras.utils.to_categorical(encoder.transform(y_test))\n",
        "print(accuracy_score(y_test, np.argmax(ann.predict(x_test), axis=1)))\n",
        "print(f1_score(y_test, np.argmax(ann.predict(x_test), axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## nearest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train,x_val = train_test_split(x_train, test_size=0.2)\n",
        "y_train,y_val = train_test_split(y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_k(x_train, y_train, x_val, y_val):\n",
        "    best_k = 0\n",
        "    best_score = 0\n",
        "    for k in range(1, 11):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(x_train, y_train)\n",
        "        pred = knn.predict(x_val)\n",
        "        score = f1_score(y_val, pred, average='macro')\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_k = k\n",
        "    return best_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_best_k(x_train, y_train, x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0672147001934236\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concat train and val\n",
        "x_train = np.concatenate((x_train, x_val), axis=0)\n",
        "y_train = np.concatenate((y_train, y_val), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jahna\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        }
      ],
      "source": [
        "clf = XGBClassifier(random_state = 0)\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D\n",
        "from keras.models import Sequential,Model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.merge import Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    embeddings_index = {}\n",
        "    f = open(path2, encoding=\"utf8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "        except:\n",
        "            pass\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_index))\n",
        "    return (X_train, X_test, word_index,embeddings_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Build_Model_CNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
        "    \"\"\"\n",
        "        def buildModel_CNN(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
        "        word_index in word index ,\n",
        "        embeddings_index is embeddings index, look at data_helper.py\n",
        "        nClasses is number of classes,\n",
        "        MAX_SEQUENCE_LENGTH is maximum lenght of text sequences,\n",
        "        EMBEDDING_DIM is an int value for dimention of word embedding look at data_helper.py\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
        "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
        "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    embedding_layer = Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True)\n",
        "    # applying a more complex convolutional approach\n",
        "    convs = []\n",
        "    filter_sizes = []\n",
        "    layer = 5\n",
        "    print(\"Filter  \",layer)\n",
        "    for fl in range(0,layer):\n",
        "        filter_sizes.append((fl+2))\n",
        "    node = 128\n",
        "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    for fsz in filter_sizes:\n",
        "        l_conv = Conv1D(node, kernel_size=fsz, activation='relu')(embedded_sequences)\n",
        "        l_pool = MaxPooling1D(5)(l_conv)\n",
        "        #l_pool = Dropout(0.25)(l_pool)\n",
        "        convs.append(l_pool)\n",
        "    l_merge = Concatenate(axis=1)(convs)\n",
        "    l_cov1 = Conv1D(node, 5, activation='relu')(l_merge)\n",
        "    l_cov1 = Dropout(dropout)(l_cov1)\n",
        "    l_pool1 = MaxPooling1D(5)(l_cov1)\n",
        "    l_cov2 = Conv1D(node, 5, activation='relu')(l_pool1)\n",
        "    l_cov2 = Dropout(dropout)(l_cov2)\n",
        "    l_pool2 = MaxPooling1D(30)(l_cov2)\n",
        "    l_flat = Flatten()(l_pool2)\n",
        "    l_dense = Dense(1024, activation='relu')(l_flat)\n",
        "    l_dense = Dropout(dropout)(l_dense)\n",
        "    l_dense = Dense(512, activation='relu')(l_dense)\n",
        "    l_dense = Dropout(dropout)(l_dense)\n",
        "    preds = Dense(nclasses, activation='softmax')(l_dense)\n",
        "    model = Model(sequence_input, preds)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PRML_Proj.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
